{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### **Team members**:  \n",
        "#####           -Godwin Bime, \n",
        "#####           -Yin Yin Tan, \n",
        "#####           -Pratik Patel, \n",
        "#####           -Crystal Li"
      ],
      "metadata": {
        "id": "omwFx0P_MEDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/SentimentAnalysis/Twitter_Data.csv /content/sample_data"
      ],
      "metadata": {
        "id": "e-v-e1tNMHxo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/SentimentAnalysis/Reddit_Data.csv /content/sample_data"
      ],
      "metadata": {
        "id": "wrt1_jDl8Zyk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd sample_data/"
      ],
      "metadata": {
        "id": "y--QSI3I_ZVi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/SentimentAnalysis/train_deploy.py /content/sample_data"
      ],
      "metadata": {
        "id": "ust6xlvFq1df"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/SentimentAnalysis/requirements.txt /content/sample_data"
      ],
      "metadata": {
        "id": "C0LBd8hzsE9Z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "7ldOi-gudxiH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import warning\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sagemaker\n",
        "from sagemaker.pytorch import PyTorch\n",
        "from sagemaker.huggingface import HuggingFace\n",
        "\n",
        "import boto3\n",
        "import string\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "xztphF9ne9YP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  !aws configure"
      ],
      "metadata": {
        "id": "lvOFa5jegPVl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sagemaker_sess = sagemaker.Session()\n",
        "bucket = sagemaker_sess.default_bucket()\n",
        "prefix = \"sagemaker/ai620-group-project\"\n",
        "print(f\"\\nSession-Name: {bucket}\\n\")\n",
        "#role = sagemaker.get_execution_role()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC5zcHVpfCbx",
        "outputId": "ca1694bb-0f94-4656-b9c2-31da16d061f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Session-Name: sagemaker-us-east-1-060110317448\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    role = sagemaker.get_execution_role()\n",
        "except ValueError:\n",
        "    iam = boto3.client('iam')\n",
        "    role = iam.get_role(RoleName='SageMakerNotebookRoleAI620gp')['Role']['Arn']\n",
        "\n",
        "print(f\"Role: {role}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX9YDsysgB0U",
        "outputId": "61676be7-1d5a-40a3-b77a-bfbe6f82e8d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sagemaker:Couldn't call 'get_role' to get Role ARN from role name arn:aws:iam::060110317448:root to get Role path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Role: arn:aws:iam::060110317448:role/SageMakerNotebookRoleAI620gp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = [\"Sentence\", \"Label\"]  # [\"Tweet_ID\", \"Entity\", \"Sentiment\", \"Tweet\"]"
      ],
      "metadata": {
        "id": "opuTBOtTGvFd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tweeter dataset"
      ],
      "metadata": {
        "id": "qekoX0Dk9k5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tweeter_df = pd.read_csv(\"/content/sample_data/Twitter_Data.csv\", \n",
        "#                 #  header=None,\n",
        "#                 #  usecols=[1, 3],        \n",
        "#                  names=column_names)"
      ],
      "metadata": {
        "id": "Zaj3jDgoE8su"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reddit dataset"
      ],
      "metadata": {
        "id": "AbPRXphz9oUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reddit_df = pd.read_csv(\"/content/sample_data/Reddit_Data.csv\", \n",
        "#                 #  header=None,\n",
        "#                 #  usecols=[1, 3],        \n",
        "#                  names=column_names)"
      ],
      "metadata": {
        "id": "I5-ib6R58oNr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tweeter_df.head()"
      ],
      "metadata": {
        "id": "OEMMvlPT__NN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reddit_df.head()"
      ],
      "metadata": {
        "id": "oBNH_JSA__Ed"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merging the Tweeter and Reddit datasets"
      ],
      "metadata": {
        "id": "IJsLlQPt9fx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reddit_df.describe()"
      ],
      "metadata": {
        "id": "eZn-Os9wAgid"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_df = tweeter_df.merge(reddit_df, on=[\"Sentence\", \"Label\"])"
      ],
      "metadata": {
        "id": "1GWO3HC58n7_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_df.describe()"
      ],
      "metadata": {
        "id": "2RdpSrwGAM63"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write the dataset into a new .csv file"
      ],
      "metadata": {
        "id": "ysCXoDOX99Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_df.to_csv(\"tweeter_and_reddit.csv\")"
      ],
      "metadata": {
        "id": "wiB-yTOn97Wo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/sample_data/Twitter_Data.csv\", \n",
        "                #  header=None,\n",
        "                #  usecols=[1, 3],        \n",
        "                 names=column_names)"
      ],
      "metadata": {
        "id": "wIRARkngA8Bn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sentences = df.Sentence.values\n",
        "Labels = df.Label.values"
      ],
      "metadata": {
        "id": "kaJgKuCLLlp5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BBEHKoVDFQJ7",
        "outputId": "65fca41d-fff7-4134-d3ed-67e4ee72aa24"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence     Label\n",
              "0                                         clean_text  category\n",
              "1  when modi promised “minimum government maximum...        -1\n",
              "2  talk all the nonsense and continue all the dra...         0\n",
              "3  what did just say vote for modi  welcome bjp t...         1\n",
              "4  asking his supporters prefix chowkidar their n...         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1e574d4-a2c2-4ed0-a6c4-fd70d2778c99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clean_text</td>\n",
              "      <td>category</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>talk all the nonsense and continue all the dra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>asking his supporters prefix chowkidar their n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1e574d4-a2c2-4ed0-a6c4-fd70d2778c99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1e574d4-a2c2-4ed0-a6c4-fd70d2778c99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1e574d4-a2c2-4ed0-a6c4-fd70d2778c99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27bbk5niHGvL",
        "outputId": "2fa26cc4-e823-46bd-c25f-38ee6c67ff39"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence    4\n",
              "Label       7\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "okuekj-RHtcq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1aAclqhHQyw",
        "outputId": "e658f5af-c3e9-4fd4-c507-d0c3cb90a24a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence    0\n",
              "Label       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ovzbKwkSIBg8",
        "outputId": "da172e1a-7983-408c-9241-3f330c70ecaa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence     Label\n",
              "0                                         clean_text  category\n",
              "1  when modi promised “minimum government maximum...        -1\n",
              "2  talk all the nonsense and continue all the dra...         0\n",
              "3  what did just say vote for modi  welcome bjp t...         1\n",
              "4  asking his supporters prefix chowkidar their n...         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3edc785-0acf-49f3-ba2a-7ece8e526afb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clean_text</td>\n",
              "      <td>category</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>talk all the nonsense and continue all the dra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>asking his supporters prefix chowkidar their n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3edc785-0acf-49f3-ba2a-7ece8e526afb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3edc785-0acf-49f3-ba2a-7ece8e526afb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3edc785-0acf-49f3-ba2a-7ece8e526afb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentence'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMpxkx2gIIJ7",
        "outputId": "edc567a3-1a5a-415f-e8c8-8ef1f22c6e59"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count         162970\n",
              "unique        162970\n",
              "top       clean_text\n",
              "freq               1\n",
              "Name: Sentence, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(Sentences[80:85], Labels[80:85]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ml0QEaoJR94",
        "outputId": "5fbd8e3b-0beb-461a-be23-2d33896450d1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kitna jalte tum modi your tweet shows your jealousy towards our great prime minister modi ',\n",
              "  '1'),\n",
              " ('centre state govts working together make india tbfree 2025 ', '0'),\n",
              " ('where ever rgis going through out the length breadth the country such the reception for him masses india just love him modi all other leaders bjp are just match',\n",
              "  '1'),\n",
              " ('mad sandip singh have some sense javed akhtar could have called narendra modi producer sandip ssingh credit row entertainment news the indian express ',\n",
              "  '-1'),\n",
              " ('thanks modi porn sites are banned', '1')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrk1ajtzl6yj",
        "outputId": "3f0b60b2-930e-4082-866c-8a7f4df834c4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 162970 entries, 0 to 162980\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count   Dtype \n",
            "---  ------    --------------   ----- \n",
            " 0   Sentence  162970 non-null  object\n",
            " 1   Label     162970 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 3.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install nltk"
      ],
      "metadata": {
        "id": "aKy89-6BmuYW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "\"\"\"\n",
        "The review_to_words method defined above uses BeautifulSoup to remove \n",
        "any html tags that appear and uses the nltk package to tokenize the reviews. \n",
        "As a check to ensure we know how everything is working, try applying review_to_words \n",
        "to one of the reviews in the training set.\n",
        "\"\"\"\n",
        "\n",
        "# Remove html tags, stop words, and convert to lower case\n",
        "def review_input_words(input_review_words):\n",
        "  nltk.download(\"stopwords\", quiet=True)\n",
        "  stemmer = PorterStemmer()\n",
        "\n",
        "  text = BeautifulSoup(input_review_words, \"html.parser\").get_text()# Remove all the html tags\n",
        "  text = re.sub(r\"a-zA-Z0-9\", \" \", text.lower()) # Convert the cleaned text to lowercase\n",
        "  words = text.split() # Split the strings into words\n",
        "  words = [w for w in words if w not in stopwords.words(\"english\")] # Remove all the stop words\n",
        "  words = [PorterStemmer().stem(w) for w in words] \n",
        "\n",
        "  return words"
      ],
      "metadata": {
        "id": "ziGg5yjkMSuK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to remove URL from text, emojis and puctuatuins where necessary\n",
        "def remove_URL(u_text):\n",
        "  url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  return url.sub(r'', u_text)"
      ],
      "metadata": {
        "id": "euIPlPbKNArZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emojis(e_text):\n",
        "  em_pattern = re.compile(\"[\"\n",
        "                            u\"\\U0001F600-\\U0001F64F\"   # emojis\n",
        "                            u\"\\U0001F300-\\U0001F5FF\"   # symbols and diagrams\n",
        "                            u\"\\U0001F680-\\U0001F6FF\"   # transport & map symbols\n",
        "                            u\"\\U0001F1E0-\\U0001F1FF\"   # flags (iOS)\n",
        "                            u\"\\U00002702-\\U000027B0\"   # chinese char\n",
        "                            u\"\\U000024C2-\\U0001F251\"\n",
        "                            u\"\\U00002702-\\U000027B0\"\n",
        "                            u\"\\U00002702-\\U000027B0\"\n",
        "                            u\"\\U0001f926-\\U0001f937\"\n",
        "                               u\"\\U00010000-\\U0010ffff\"\n",
        "                               u\"\\u2640-\\u2642\"\n",
        "                               u\"\\u2600-\\u2B55\"\n",
        "                               u\"\\u200d\"\n",
        "                               u\"\\u23cf\"\n",
        "                               u\"\\u23e9\"\n",
        "                               u\"\\u231a\"\n",
        "                               u\"\\ufe0f\"  # dingbats\n",
        "                               u\"\\u3030\"\n",
        "                            \"]+\", flags=re.UNICODE)\n",
        "  return em_pattern.sub(r'', e_text)"
      ],
      "metadata": {
        "id": "6IaU0gyckWrN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html(h_text):\n",
        "  h_tag = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
        "  h_text = h_tag.sub(r'', h_text)\n",
        "  return h_text"
      ],
      "metadata": {
        "id": "9Vazl4WIkWns"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(p_text):\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  return p_text.translate(table)"
      ],
      "metadata": {
        "id": "4Dt3yueekWlv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean the data"
      ],
      "metadata": {
        "id": "LZCne-pQnaST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentence'] = df['Sentence'].apply(lambda u_x: remove_URL(u_x))\n",
        "df['Sentence'] = df['Sentence'].apply(lambda p_x: remove_punctuation(p_x))\n",
        "df['Sentence'] = df['Sentence'].apply(lambda e_x: remove_emojis(e_x))\n",
        "df['Sentence'] = df['Sentence'].apply(lambda h_x: remove_html(h_x))\n",
        "#df['Sentence'] = df['Sentence'].apply(lambda r_x: review_input_words(r_x))"
      ],
      "metadata": {
        "id": "PjKRAntqkWjG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pTTuoTU7kWX1",
        "outputId": "0589488c-9cd4-4751-b014-cf4fb791a592"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence     Label\n",
              "0                                          cleantext  category\n",
              "1  when modi promised “minimum government maximum...        -1\n",
              "2  talk all the nonsense and continue all the dra...         0\n",
              "3  what did just say vote for modi  welcome bjp t...         1\n",
              "4  asking his supporters prefix chowkidar their n...         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbc9ad50-41ff-4848-943b-cd796045cf8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cleantext</td>\n",
              "      <td>category</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>talk all the nonsense and continue all the dra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>asking his supporters prefix chowkidar their n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbc9ad50-41ff-4848-943b-cd796045cf8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bbc9ad50-41ff-4848-943b-cd796045cf8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bbc9ad50-41ff-4848-943b-cd796045cf8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sentences = df.Sentence.values\n",
        "Labels = df.Label.values"
      ],
      "metadata": {
        "id": "CQmSJmv3oOsj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(Sentences[80:85], Labels[80:85]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo1nkk3OoOpF",
        "outputId": "dff4a77f-5a11-41ca-de17-17760406f5e6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kitna jalte tum modi your tweet shows your jealousy towards our great prime minister modi ',\n",
              "  '1'),\n",
              " ('centre state govts working together make india tbfree 2025 ', '0'),\n",
              " ('where ever rgis going through out the length breadth the country such the reception for him masses india just love him modi all other leaders bjp are just match',\n",
              "  '1'),\n",
              " ('mad sandip singh have some sense javed akhtar could have called narendra modi producer sandip ssingh credit row entertainment news the indian express ',\n",
              "  '-1'),\n",
              " ('thanks modi porn sites are banned', '1')]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Distribution"
      ],
      "metadata": {
        "id": "78GOJ5ufo7Vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Sentence\"][:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wu-X_b0KALk",
        "outputId": "bb4e76d0-f352-4b95-b997-2e5e3e04d9af"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                            cleantext\n",
              "1    when modi promised “minimum government maximum...\n",
              "2    talk all the nonsense and continue all the dra...\n",
              "3    what did just say vote for modi  welcome bjp t...\n",
              "4    asking his supporters prefix chowkidar their n...\n",
              "Name: Sentence, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df['Sentence'].str.len(), binwidth=50)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "-SIvImKIHfwE",
        "outputId": "46325231-069e-47d5-e5ce-141cb679ab07"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax = plt.subplots(1, 2, figsize=(12,6))\n",
        "# ax[0].pie(df['Label'].value_counts(), labels=df['Label'].value_counts().index, autopct='%.f%%')\n",
        "# fig.suptitle(\"Proportions of target classes\")\n",
        "# ax[0].set_title(\"Train dataset\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "2ijMib1SMQ_S"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Label').describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "oRGyA44PHfpt",
        "outputId": "938ddc35-5fa5-4abd-e814-b65b895131e1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Sentence                                                            \\\n",
              "            count unique                                                top   \n",
              "Label                                                                         \n",
              "-1          35509  35504  the modi govt approved scheduled tribe status ...   \n",
              "0           55211  55183                                         only modi    \n",
              "1           72249  72223  modi’ rally rudrapur people say ‘main bhi chow...   \n",
              "category        1      1                                          cleantext   \n",
              "\n",
              "               \n",
              "         freq  \n",
              "Label          \n",
              "-1          2  \n",
              "0           5  \n",
              "1           2  \n",
              "category    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d69b893a-a075-47af-89a6-9b7d3e86424d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">Sentence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-1</th>\n",
              "      <td>35509</td>\n",
              "      <td>35504</td>\n",
              "      <td>the modi govt approved scheduled tribe status ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55211</td>\n",
              "      <td>55183</td>\n",
              "      <td>only modi</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>72249</td>\n",
              "      <td>72223</td>\n",
              "      <td>modi’ rally rudrapur people say ‘main bhi chow...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>cleantext</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d69b893a-a075-47af-89a6-9b7d3e86424d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d69b893a-a075-47af-89a6-9b7d3e86424d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d69b893a-a075-47af-89a6-9b7d3e86424d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the dataset for training and testing"
      ],
      "metadata": {
        "id": "Jfu-M-dkTpHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df)\n",
        "train.to_csv(\"/content/sample_data/train.csv\")\n",
        "test.to_csv(\"/content/sample_data/test.csv\")"
      ],
      "metadata": {
        "id": "sfrrfUWqT8xs"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload both train and test dataset to s3 bucket for later use"
      ],
      "metadata": {
        "id": "b2QEM6ZIUi0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_train = sagemaker_sess.upload_data(\"/content/sample_data/train.csv\", bucket=bucket, key_prefix=prefix)\n",
        "input_test = sagemaker_sess.upload_data(\"/content/sample_data/test.csv\", bucket=bucket, key_prefix=prefix)"
      ],
      "metadata": {
        "id": "b2NTt57cT8uQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL6PxOzVN6QU",
        "outputId": "6fad5b0b-a7c2-484b-adfd-d4cd1b8eefba"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s3://sagemaker-us-east-1-060110317448/sagemaker/ai620-group-project/train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pygmentize /content/sample_data/train_deploy.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmx04gp5T8rx",
        "outputId": "5fe4c1dd-f2b0-4e01-deb5-2946f9f75203"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdatasets\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m load_from_disk\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m accuracy_score, precision_recall_fscore_support\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mwandb\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "wandb.login(key=\u001b[33m\"\u001b[39;49;00m\u001b[33m7c897087ac4638f26fb916ad0b8c4aa0437b64ad\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)  \u001b[37m# Pass your W&B API key here\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "wandb.init(project=\u001b[33m\"\u001b[39;49;00m\u001b[33mSentimentAnalysis\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)  \u001b[37m# Add your W&B project name\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# compute metrics function for binary classification\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mdef\u001b[39;49;00m \u001b[32mcompute_metrics\u001b[39;49;00m(pred):\u001b[37m\u001b[39;49;00m\n",
            "    labels = pred.label_ids\u001b[37m\u001b[39;49;00m\n",
            "    preds = pred.predictions.argmax(-\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\u001b[33m\"\u001b[39;49;00m\u001b[33mbinary\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    acc = accuracy_score(labels, preds)\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mreturn\u001b[39;49;00m {\u001b[33m\"\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: acc, \u001b[33m\"\u001b[39;49;00m\u001b[33mf1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: f1, \u001b[33m\"\u001b[39;49;00m\u001b[33mprecision\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: precision, \u001b[33m\"\u001b[39;49;00m\u001b[33mrecall\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: recall}\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(args):\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[37m# Set up logging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    logging.basicConfig(\u001b[37m\u001b[39;49;00m\n",
            "        level=logging.getLevelName(\u001b[33m\"\u001b[39;49;00m\u001b[33mINFO\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
            "        handlers=[logging.StreamHandler(sys.stdout)],\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[36mformat\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m%(asctime)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(name)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(levelname)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(message)s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
            "    )\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[37m# load datasets\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    train_dataset = load_from_disk(args.training_dir)\u001b[37m\u001b[39;49;00m\n",
            "    test_dataset = load_from_disk(args.test_dir)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m loaded train_dataset length is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mlen\u001b[39;49;00m(train_dataset)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m loaded test_dataset length is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mlen\u001b[39;49;00m(test_dataset)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[37m# download model from model hub\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    model = AutoModelForSequenceClassification.from_pretrained(args.model_name)\u001b[37m\u001b[39;49;00m\n",
            "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[37m# define training args\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    training_args = TrainingArguments(\u001b[37m\u001b[39;49;00m\n",
            "        output_dir=args.checkpoints,\u001b[37m\u001b[39;49;00m\n",
            "        num_train_epochs=args.epochs,\u001b[37m\u001b[39;49;00m\n",
            "        per_device_train_batch_size=args.train_batch_size,\u001b[37m\u001b[39;49;00m\n",
            "        per_device_eval_batch_size=args.eval_batch_size,\u001b[37m\u001b[39;49;00m\n",
            "        warmup_steps=args.warmup_steps,\u001b[37m\u001b[39;49;00m\n",
            "        evaluation_strategy=\u001b[33m\"\u001b[39;49;00m\u001b[33mepoch\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
            "        logging_dir=\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.checkpoints\u001b[33m}\u001b[39;49;00m\u001b[33m/logs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
            "        learning_rate=args.learning_rate,\u001b[37m\u001b[39;49;00m\n",
            "        report_to=\u001b[33m\"\u001b[39;49;00m\u001b[33mwandb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    )\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[37m# create Trainer instance\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    trainer = Trainer(\u001b[37m\u001b[39;49;00m\n",
            "        model=model,\u001b[37m\u001b[39;49;00m\n",
            "        args=training_args,\u001b[37m\u001b[39;49;00m\n",
            "        compute_metrics=compute_metrics,\u001b[37m\u001b[39;49;00m\n",
            "        train_dataset=train_dataset,\u001b[37m\u001b[39;49;00m\n",
            "        eval_dataset=test_dataset,\u001b[37m\u001b[39;49;00m\n",
            "        tokenizer=tokenizer,\u001b[37m\u001b[39;49;00m\n",
            "    )\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[37m# train model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    trainer.train()\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[37m# evaluate model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    eval_result = trainer.evaluate(eval_dataset=test_dataset)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[37m# writes eval result to file which can be accessed later in s3 ouput\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(args.checkpoints, \u001b[33m\"\u001b[39;49;00m\u001b[33meval_results.txt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m writer:\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m***** Eval results *****\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mfor\u001b[39;49;00m key, value \u001b[35min\u001b[39;49;00m \u001b[36msorted\u001b[39;49;00m(eval_result.items()):\u001b[37m\u001b[39;49;00m\n",
            "            writer.write(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mkey\u001b[33m}\u001b[39;49;00m\u001b[33m = \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvalue\u001b[33m}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[37m# Saves the model locally. In SageMaker, writing in /opt/ml/model sends it to S3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    trainer.save_model(args.model_dir)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m# Inference related functions\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
            "\u001b[33m    Load the model for inference\u001b[39;49;00m\n",
            "\u001b[33m    \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    model_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[37m# Load BERT tokenizer from disk.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    tokenizer = AutoTokenizer.from_pretrained(model_path)\u001b[37m\u001b[39;49;00m\n",
            "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    test_args = TrainingArguments(\u001b[37m\u001b[39;49;00m\n",
            "        output_dir=model_path,\u001b[37m\u001b[39;49;00m\n",
            "        do_train=\u001b[34mFalse\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
            "        do_predict=\u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
            "        per_device_eval_batch_size=\u001b[34m32\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
            "        dataloader_drop_last=\u001b[34mFalse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    )\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    trainer = Trainer(\u001b[37m\u001b[39;49;00m\n",
            "        model=model.to(device),\u001b[37m\u001b[39;49;00m\n",
            "        args=test_args,\u001b[37m\u001b[39;49;00m\n",
            "        compute_metrics=compute_metrics)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    model_dict = {\u001b[33m'\u001b[39;49;00m\u001b[33mtrainer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: trainer, \u001b[33m'\u001b[39;49;00m\u001b[33mtokenizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tokenizer}\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mreturn\u001b[39;49;00m model_dict\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, model_dict):\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
            "\u001b[33m    Apply model to the incoming request\u001b[39;49;00m\n",
            "\u001b[33m    \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    trainer = model_dict[\u001b[33m'\u001b[39;49;00m\u001b[33mtrainer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
            "    tokenizer = model_dict[\u001b[33m'\u001b[39;49;00m\u001b[33mtokenizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "        data = {\u001b[33m\"\u001b[39;49;00m\u001b[33msuccess\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34mFalse\u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
            "        input_text = input_data[\u001b[33m'\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "        encoding = tokenizer(input_text, padding=\u001b[33m\"\u001b[39;49;00m\u001b[33mmax_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, truncation=\u001b[34mTrue\u001b[39;49;00m, max_length=\u001b[34m128\u001b[39;49;00m, return_tensors=\u001b[33m\"\u001b[39;49;00m\u001b[33mpt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "        encoding = {k: v.to(trainer.model.device) \u001b[34mfor\u001b[39;49;00m k, v \u001b[35min\u001b[39;49;00m encoding.items()}\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "        outputs = trainer.model(**encoding)\u001b[37m\u001b[39;49;00m\n",
            "        logits = outputs.logits\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[37m# get probabilities for each topic\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "        sigmoid = torch.nn.Sigmoid()\u001b[37m\u001b[39;49;00m\n",
            "        probs = sigmoid(logits.squeeze().cpu())\u001b[37m\u001b[39;49;00m\n",
            "        predictions = np.zeros(probs.shape)\u001b[37m\u001b[39;49;00m\n",
            "        predictions[np.where(probs >= \u001b[34m0.5\u001b[39;49;00m)] = \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "        probs = probs.cpu().detach().numpy()\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "        predictions = predictions.reshape(\u001b[34m1\u001b[39;49;00m, -\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "        probs = probs.reshape(\u001b[34m1\u001b[39;49;00m, -\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mif\u001b[39;49;00m probs[\u001b[34m0\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] > probs[\u001b[34m0\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m]:\u001b[37m\u001b[39;49;00m\n",
            "            results = {\u001b[33m\"\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mNegative\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mscore\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: probs[\u001b[34m0\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m]}\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "            results = {\u001b[33m\"\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mPositive\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mscore\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: probs[\u001b[34m0\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m]}\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mreturn\u001b[39;49;00m results\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\u001b[37m\u001b[39;49;00m\n",
            "        data = {\u001b[33m\"\u001b[39;49;00m\u001b[33msuccess\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34mFalse\u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
            "        data[\u001b[33m'\u001b[39;49;00m\u001b[33msentiments\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[33m'\u001b[39;49;00m\u001b[33mNULL\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mUnexpected error in predict_fn:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, e)\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mreturn\u001b[39;49;00m json.dumps(data)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(request_body, request_content_type):\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
            "\u001b[33m    Deserialize and prepare the prediction input\u001b[39;49;00m\n",
            "\u001b[33m    \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mif\u001b[39;49;00m request_content_type == \u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "            request = json.loads(request_body)\u001b[37m\u001b[39;49;00m\n",
            "            \u001b[34mreturn\u001b[39;49;00m request\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mexcept\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "            \u001b[34mreturn\u001b[39;49;00m request_body\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "        request = request_body\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[37m# hyperparameters sent by the client are passed as command-line arguments to the script.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m3\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--train_batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m32\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--eval_batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--warmup_steps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m500\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--learning_rate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m5e-5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--checkpoints\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/checkpoints/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.path.join(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], \u001b[33m'\u001b[39;49;00m\u001b[33mmodel/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
            "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_gpus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
            "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--training_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
            "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--test_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TEST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    train(parser.parse_args())\u001b[37m\u001b[39;49;00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training on Amazon SageMaker using on-demand instances with Epoch=2"
      ],
      "metadata": {
        "id": "XcqRipJE1qwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = PyTorch(entry_point=\"train_deploy.py\",\n",
        "                    source_dir=\"/content/sample_data\",\n",
        "                    role=role,\n",
        "                    framework_version=\"1.9\",\n",
        "                    py_version=\"py38\",\n",
        "                    instance_count=1,\n",
        "                    instance_type=\"ml.m5.xlarge\",\n",
        "                    Hyperparameters={\"epochs\": 2,\n",
        "                                     \"num_labels\": 2,})"
      ],
      "metadata": {
        "id": "GdMtg_hlT8pf"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# estimator.fit({\"training\": input_train, \"testing\": input_test})\n",
        "estimator.fit({\"training\": input_train, \"testing\": input_test})"
      ],
      "metadata": {
        "id": "jHq-cQnXHfnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c964df8e-b2f9-486c-da99-ba60e2657083"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using provided s3_resource\n",
            "2023-06-10 14:52:38 Starting - Starting the training job...\n",
            "2023-06-10 14:52:53 Starting - Preparing the instances for training......\n",
            "2023-06-10 14:54:10 Downloading - Downloading input data\n",
            "2023-06-10 14:54:10 Training - Downloading the training image...\n",
            "2023-06-10 14:54:41 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
            "\u001b[34mbash: no job control in this shell\u001b[0m\n",
            "\u001b[34m2023-06-10 14:54:50,252 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
            "\u001b[34m2023-06-10 14:54:50,255 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2023-06-10 14:54:50,263 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
            "\u001b[34m2023-06-10 14:54:50,266 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
            "\u001b[34m2023-06-10 14:54:51,210 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
            "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
            "\u001b[34mCollecting datasets\u001b[0m\n",
            "\u001b[34mDownloading datasets-2.12.0-py3-none-any.whl (474 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 474.6/474.6 kB 43.8 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting wandb\u001b[0m\n",
            "\u001b[34mDownloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 97.7 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (4.64.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (2.27.1)\u001b[0m\n",
            "\u001b[34mCollecting transformers\u001b[0m\n",
            "\u001b[34mDownloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.2/7.2 MB 110.2 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.0.2)\u001b[0m\n",
            "\u001b[34mCollecting nvgpu\u001b[0m\n",
            "\u001b[34mDownloading nvgpu-0.10.0.tar.gz (8.4 kB)\u001b[0m\n",
            "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
            "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: awscli in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.25.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (2.92.2)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: boto3 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (1.24.1)\u001b[0m\n",
            "\u001b[34mCollecting xgboost\u001b[0m\n",
            "\u001b[34mDownloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.3/200.3 MB 10.2 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pyarrow in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (8.0.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (1.1.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (2022.5.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (1.22.2)\u001b[0m\n",
            "\u001b[34mCollecting xxhash\u001b[0m\n",
            "\u001b[34mDownloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 213.0/213.0 kB 52.5 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (0.70.13)\u001b[0m\n",
            "\u001b[34mCollecting responses<0.19\u001b[0m\n",
            "\u001b[34mDownloading responses-0.18.0-py3-none-any.whl (38 kB)\u001b[0m\n",
            "\u001b[34mCollecting huggingface-hub<1.0.0,>=0.11.0\u001b[0m\n",
            "\u001b[34mDownloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 236.8/236.8 kB 44.3 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting aiohttp\u001b[0m\n",
            "\u001b[34mDownloading aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 97.0 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (0.3.5.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (21.3)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (1.4.2)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 2)) (4.2.0)\u001b[0m\n",
            "\u001b[34mCollecting GitPython!=3.1.29,>=1.0.0\u001b[0m\n",
            "\u001b[34mDownloading GitPython-3.1.31-py3-none-any.whl (184 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.3/184.3 kB 46.8 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting pathtools\u001b[0m\n",
            "\u001b[34mDownloading pathtools-0.1.2.tar.gz (11 kB)\u001b[0m\n",
            "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
            "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 2)) (3.20.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 2)) (5.6.7)\u001b[0m\n",
            "\u001b[34mCollecting sentry-sdk>=1.0.0\u001b[0m\n",
            "\u001b[34mDownloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 206.7/206.7 kB 46.3 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 2)) (8.1.3)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 2)) (62.3.2)\u001b[0m\n",
            "\u001b[34mCollecting setproctitle\u001b[0m\n",
            "\u001b[34mDownloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\u001b[0m\n",
            "\u001b[34mCollecting docker-pycreds>=0.4.0\u001b[0m\n",
            "\u001b[34mDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\u001b[0m\n",
            "\u001b[34mCollecting appdirs>=1.4.3\u001b[0m\n",
            "\u001b[34mDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 4)) (1.26.9)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 4)) (2.0.4)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 4)) (3.3)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 4)) (2022.5.18.1)\u001b[0m\n",
            "\u001b[34mCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\u001b[0m\n",
            "\u001b[34mDownloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 70.2 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting safetensors>=0.3.1\u001b[0m\n",
            "\u001b[34mDownloading safetensors-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 86.9 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting regex!=2019.12.17\u001b[0m\n",
            "\u001b[34mDownloading regex-2023.6.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 772.3/772.3 kB 83.3 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting filelock\u001b[0m\n",
            "\u001b[34mDownloading filelock-3.12.1-py3-none-any.whl (10 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.8.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 6)) (2.2.0)\u001b[0m\n",
            "\u001b[34mCollecting ansi2html\u001b[0m\n",
            "\u001b[34mDownloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\u001b[0m\n",
            "\u001b[34mCollecting arrow\u001b[0m\n",
            "\u001b[34mDownloading arrow-1.2.3-py3-none-any.whl (66 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.4/66.4 kB 21.7 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting flask\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.3.2-py3-none-any.whl (96 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.9/96.9 kB 23.2 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting flask_restful\u001b[0m\n",
            "\u001b[34mDownloading Flask_RESTful-0.3.10-py2.py3-none-any.whl (26 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 7)) (1.16.0)\u001b[0m\n",
            "\u001b[34mCollecting termcolor\u001b[0m\n",
            "\u001b[34mDownloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 7)) (0.8.9)\u001b[0m\n",
            "\u001b[34mCollecting pynvml\u001b[0m\n",
            "\u001b[34mDownloading pynvml-11.5.0-py3-none-any.whl (53 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 15.5 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: rsa<4.8,>=3.1.2 in /opt/conda/lib/python3.8/site-packages (from awscli->-r requirements.txt (line 8)) (4.7.2)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: docutils<0.17,>=0.10 in /opt/conda/lib/python3.8/site-packages (from awscli->-r requirements.txt (line 8)) (0.16)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: botocore==1.27.1 in /opt/conda/lib/python3.8/site-packages (from awscli->-r requirements.txt (line 8)) (1.27.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: colorama<0.4.5,>=0.2.5 in /opt/conda/lib/python3.8/site-packages (from awscli->-r requirements.txt (line 8)) (0.4.4)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from awscli->-r requirements.txt (line 8)) (0.6.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore==1.27.1->awscli->-r requirements.txt (line 8)) (2.8.2)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from botocore==1.27.1->awscli->-r requirements.txt (line 8)) (1.0.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: importlib-metadata<2.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 9)) (1.7.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 9)) (1.0.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: attrs==20.3.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 9)) (20.3.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 9)) (0.1.5)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 9)) (0.2.9)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 9)) (0.2.0)\u001b[0m\n",
            "\u001b[34mCollecting gitdb<5,>=4.0.1\u001b[0m\n",
            "\u001b[34mDownloading gitdb-4.0.10-py3-none-any.whl (62 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 19.4 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<2.0,>=1.4.0->sagemaker->-r requirements.txt (line 9)) (3.8.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets->-r requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from rsa<4.8,>=3.1.2->awscli->-r requirements.txt (line 8)) (0.4.8)\u001b[0m\n",
            "\u001b[34mCollecting urllib3<1.27,>=1.21.1\u001b[0m\n",
            "\u001b[34mDownloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.1/143.1 kB 42.9 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting yarl<2.0,>=1.0\u001b[0m\n",
            "\u001b[34mDownloading yarl-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 266.9/266.9 kB 52.5 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting multidict<7.0,>=4.5\u001b[0m\n",
            "\u001b[34mDownloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 27.7 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting aiosignal>=1.1.2\u001b[0m\n",
            "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
            "\u001b[34mCollecting frozenlist>=1.1.1\u001b[0m\n",
            "\u001b[34mDownloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 34.7 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
            "\u001b[34mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
            "\u001b[34mCollecting itsdangerous>=2.1.2\u001b[0m\n",
            "\u001b[34mDownloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 7)) (3.1.2)\u001b[0m\n",
            "\u001b[34mCollecting blinker>=1.6.2\u001b[0m\n",
            "\u001b[34mDownloading blinker-1.6.2-py3-none-any.whl (13 kB)\u001b[0m\n",
            "\u001b[34mCollecting flask\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.3.1-py3-none-any.whl (96 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.0/97.0 kB 29.6 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.3.0-py3-none-any.whl (96 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.0/97.0 kB 30.5 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.2.5-py3-none-any.whl (101 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.8/101.8 kB 8.1 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.2.4-py3-none-any.whl (101 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.7/101.7 kB 28.3 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.2.3-py3-none-any.whl (101 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.8/101.8 kB 31.2 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.2.2-py3-none-any.whl (101 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.5/101.5 kB 22.9 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.2.1-py3-none-any.whl (101 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.5/101.5 kB 31.3 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.2.0-py3-none-any.whl (101 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.1/101.1 kB 27.2 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.1.3-py3-none-any.whl (95 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.6/95.6 kB 29.0 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.1.2-py3-none-any.whl (95 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.2/95.2 kB 28.4 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.1.1-py3-none-any.whl (95 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.2/95.2 kB 20.1 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.1.0-py3-none-any.whl (95 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.2/95.2 kB 29.1 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: Werkzeug>=2.0 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 7)) (2.1.2)\u001b[0m\n",
            "\u001b[34mCollecting aniso8601>=0.82\u001b[0m\n",
            "\u001b[34mDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 16.7 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pytz in /opt/conda/lib/python3.8/site-packages (from flask_restful->nvgpu->-r requirements.txt (line 7)) (2021.3)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: ppft>=1.7.6.5 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker->-r requirements.txt (line 9)) (1.7.6.5)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pox>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker->-r requirements.txt (line 9)) (0.3.1)\u001b[0m\n",
            "\u001b[34mCollecting smmap<6,>=3.0.1\u001b[0m\n",
            "\u001b[34mDownloading smmap-5.0.0-py3-none-any.whl (24 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from Jinja2>=3.1.2->flask->nvgpu->-r requirements.txt (line 7)) (2.1.1)\u001b[0m\n",
            "\u001b[34mBuilding wheels for collected packages: nvgpu, pathtools\u001b[0m\n",
            "\u001b[34mBuilding wheel for nvgpu (setup.py): started\u001b[0m\n",
            "\u001b[34mBuilding wheel for nvgpu (setup.py): finished with status 'done'\u001b[0m\n",
            "\u001b[34mCreated wheel for nvgpu: filename=nvgpu-0.10.0-py3-none-any.whl size=9543 sha256=d1dd26c2ecefb951fc9c17121d63ba52ff956a1232c200cb75348626abe97df0\u001b[0m\n",
            "\u001b[34mStored in directory: /root/.cache/pip/wheels/b2/af/59/68aadfe227fc8fd079544b719d3aaaf4067d68990bbc2c79e5\u001b[0m\n",
            "\u001b[34mBuilding wheel for pathtools (setup.py): started\u001b[0m\n",
            "\u001b[34mBuilding wheel for pathtools (setup.py): finished with status 'done'\u001b[0m\n",
            "\u001b[34mCreated wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=cd166a8b14738ced922256ab46a1715bd84728b8ad42f38eb852766e88baecde\u001b[0m\n",
            "\u001b[34mStored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\u001b[0m\n",
            "\u001b[34mSuccessfully built nvgpu pathtools\u001b[0m\n",
            "\u001b[34mInstalling collected packages: tokenizers, safetensors, pathtools, appdirs, aniso8601, xxhash, urllib3, termcolor, smmap, setproctitle, regex, pynvml, multidict, itsdangerous, frozenlist, filelock, docker-pycreds, async-timeout, ansi2html, yarl, xgboost, sentry-sdk, gitdb, flask, arrow, aiosignal, responses, huggingface-hub, GitPython, flask_restful, aiohttp, wandb, transformers, nvgpu, datasets\u001b[0m\n",
            "\u001b[34mAttempting uninstall: urllib3\u001b[0m\n",
            "\u001b[34mFound existing installation: urllib3 1.26.9\u001b[0m\n",
            "\u001b[34mUninstalling urllib3-1.26.9:\u001b[0m\n",
            "\u001b[34mSuccessfully uninstalled urllib3-1.26.9\u001b[0m\n",
            "\u001b[34mSuccessfully installed GitPython-3.1.31 aiohttp-3.8.4 aiosignal-1.3.1 aniso8601-9.0.1 ansi2html-1.8.0 appdirs-1.4.4 arrow-1.2.3 async-timeout-4.0.2 datasets-2.12.0 docker-pycreds-0.4.0 filelock-3.12.1 flask-2.1.0 flask_restful-0.3.10 frozenlist-1.3.3 gitdb-4.0.10 huggingface-hub-0.15.1 itsdangerous-2.1.2 multidict-6.0.4 nvgpu-0.10.0 pathtools-0.1.2 pynvml-11.5.0 regex-2023.6.3 responses-0.18.0 safetensors-0.3.1 sentry-sdk-1.25.1 setproctitle-1.3.2 smmap-5.0.0 termcolor-2.3.0 tokenizers-0.13.3 transformers-4.30.1 urllib3-1.26.16 wandb-0.15.4 xgboost-1.7.5 xxhash-3.2.0 yarl-1.9.2\u001b[0m\n",
            "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[34m2023-06-10 14:55:16,118 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
            "\u001b[34m2023-06-10 14:55:16,119 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
            "\u001b[34m2023-06-10 14:55:16,122 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2023-06-10 14:55:16,133 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2023-06-10 14:55:16,144 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2023-06-10 14:55:16,153 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
            "\u001b[34mTraining Env:\u001b[0m\n",
            "\u001b[34m{\n",
            "    \"additional_framework_parameters\": {},\n",
            "    \"channel_input_dirs\": {\n",
            "        \"testing\": \"/opt/ml/input/data/testing\",\n",
            "        \"training\": \"/opt/ml/input/data/training\"\n",
            "    },\n",
            "    \"current_host\": \"algo-1\",\n",
            "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
            "    \"hosts\": [\n",
            "        \"algo-1\"\n",
            "    ],\n",
            "    \"hyperparameters\": {},\n",
            "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
            "    \"input_data_config\": {\n",
            "        \"testing\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        },\n",
            "        \"training\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        }\n",
            "    },\n",
            "    \"input_dir\": \"/opt/ml/input\",\n",
            "    \"is_master\": true,\n",
            "    \"job_name\": \"pytorch-training-2023-06-10-14-52-20-933\",\n",
            "    \"log_level\": 20,\n",
            "    \"master_hostname\": \"algo-1\",\n",
            "    \"model_dir\": \"/opt/ml/model\",\n",
            "    \"module_dir\": \"s3://sagemaker-us-east-1-060110317448/pytorch-training-2023-06-10-14-52-20-933/source/sourcedir.tar.gz\",\n",
            "    \"module_name\": \"train_deploy\",\n",
            "    \"network_interface_name\": \"eth0\",\n",
            "    \"num_cpus\": 4,\n",
            "    \"num_gpus\": 0,\n",
            "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
            "    \"output_dir\": \"/opt/ml/output\",\n",
            "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
            "    \"resource_config\": {\n",
            "        \"current_host\": \"algo-1\",\n",
            "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
            "        \"current_group_name\": \"homogeneousCluster\",\n",
            "        \"hosts\": [\n",
            "            \"algo-1\"\n",
            "        ],\n",
            "        \"instance_groups\": [\n",
            "            {\n",
            "                \"instance_group_name\": \"homogeneousCluster\",\n",
            "                \"instance_type\": \"ml.m5.xlarge\",\n",
            "                \"hosts\": [\n",
            "                    \"algo-1\"\n",
            "                ]\n",
            "            }\n",
            "        ],\n",
            "        \"network_interface_name\": \"eth0\"\n",
            "    },\n",
            "    \"user_entry_point\": \"train_deploy.py\"\u001b[0m\n",
            "\u001b[34m}\u001b[0m\n",
            "\u001b[34mEnvironment variables:\u001b[0m\n",
            "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
            "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
            "\u001b[34mSM_HPS={}\u001b[0m\n",
            "\u001b[34mSM_USER_ENTRY_POINT=train_deploy.py\u001b[0m\n",
            "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
            "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
            "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
            "\u001b[34mSM_CHANNELS=[\"testing\",\"training\"]\u001b[0m\n",
            "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
            "\u001b[34mSM_MODULE_NAME=train_deploy\u001b[0m\n",
            "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
            "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
            "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
            "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
            "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
            "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
            "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
            "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-060110317448/pytorch-training-2023-06-10-14-52-20-933/source/sourcedir.tar.gz\u001b[0m\n",
            "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2023-06-10-14-52-20-933\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-060110317448/pytorch-training-2023-06-10-14-52-20-933/source/sourcedir.tar.gz\",\"module_name\":\"train_deploy\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_deploy.py\"}\u001b[0m\n",
            "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
            "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
            "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
            "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
            "\u001b[34mInvoking script with the following command:\u001b[0m\n",
            "\u001b[34m/opt/conda/bin/python3.8 train_deploy.py\u001b[0m\n",
            "\u001b[34m2023-06-10 14:55:16,178 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
            "\u001b[34m2023-06-10 14:55:16,178 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
            "\u001b[34m2023-06-10 14:55:16,178 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
            "\n",
            "2023-06-10 14:55:27 Uploading - Uploading generated training model\n",
            "2023-06-10 14:55:27 Completed - Training job completed\n",
            "Training seconds: 101\n",
            "Billable seconds: 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training on Amazon SageMaker using spot instances"
      ],
      "metadata": {
        "id": "_Vf5Nn_c1ctn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = PyTorch(entry_point=\"train_deploy.py\",\n",
        "                    source_dir=\"/content/sample_data\",\n",
        "                    role=role,\n",
        "                    framework_version=\"1.9\",\n",
        "                    py_version=\"py38\",\n",
        "                    instance_count=1,\n",
        "                    instance_type=\"ml.m5.xlarge\",\n",
        "                    hyperparameters={\"epochs\": 2,\n",
        "                                     \"num_labels\": 2,},\n",
        "                    use_spot_instances=True,\n",
        "                    max_run=4000,\n",
        "                    max_wait=5000)"
      ],
      "metadata": {
        "id": "cijb33LR1xXC"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator.fit({\"training\": input_train, \"testing\": input_test})"
      ],
      "metadata": {
        "id": "5u7bjvkl1xTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1aa37bf-4e12-4be7-99d4-08c035ea2519"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using provided s3_resource\n",
            "2023-06-10 14:59:02 Starting - Starting the training job...\n",
            "2023-06-10 14:59:17 Starting - Preparing the instances for training......\n",
            "2023-06-10 15:00:24 Downloading - Downloading input data...\n",
            "2023-06-10 15:00:45 Training - Downloading the training image...\n",
            "2023-06-10 15:01:20 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
            "\u001b[34mbash: no job control in this shell\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:29,922 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:29,925 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:29,935 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:29,937 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:30,812 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
            "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
            "\u001b[34mCollecting datasets\u001b[0m\n",
            "\u001b[34mDownloading datasets-2.12.0-py3-none-any.whl (474 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 474.6/474.6 kB 40.0 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting wandb\u001b[0m\n",
            "\u001b[34mDownloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 71.0 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (4.64.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (2.27.1)\u001b[0m\n",
            "\u001b[34mCollecting transformers\u001b[0m\n",
            "\u001b[34mDownloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.2/7.2 MB 87.3 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.0.2)\u001b[0m\n",
            "\u001b[34mCollecting nvgpu\u001b[0m\n",
            "\u001b[34mDownloading nvgpu-0.10.0.tar.gz (8.4 kB)\u001b[0m\n",
            "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
            "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: awscli in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.25.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (2.92.2)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: boto3 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (1.24.1)\u001b[0m\n",
            "\u001b[34mCollecting xgboost\u001b[0m\n",
            "\u001b[34mDownloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.3/200.3 MB 8.0 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pyarrow in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (8.0.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (1.1.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (0.3.5.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (21.3)\u001b[0m\n",
            "\u001b[34mCollecting responses<0.19\u001b[0m\n",
            "\u001b[34mDownloading responses-0.18.0-py3-none-any.whl (38 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (1.4.2)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (1.22.2)\u001b[0m\n",
            "\u001b[34mCollecting huggingface-hub<1.0.0,>=0.11.0\u001b[0m\n",
            "\u001b[34mDownloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 236.8/236.8 kB 42.6 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (2022.5.0)\u001b[0m\n",
            "\u001b[34mCollecting aiohttp\u001b[0m\n",
            "\u001b[34mDownloading aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 79.3 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (0.70.13)\u001b[0m\n",
            "\u001b[34mCollecting xxhash\u001b[0m\n",
            "\u001b[34mDownloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 213.0/213.0 kB 38.3 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
            "\u001b[34mCollecting setproctitle\u001b[0m\n",
            "\u001b[34mDownloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 2)) (5.6.7)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 2)) (8.1.3)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 2)) (3.20.1)\u001b[0m\n",
            "\u001b[34mCollecting appdirs>=1.4.3\u001b[0m\n",
            "\u001b[34mDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 2)) (4.2.0)\u001b[0m\n",
            "\u001b[34mCollecting sentry-sdk>=1.0.0\u001b[0m\n",
            "\u001b[34mDownloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 206.7/206.7 kB 43.3 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting pathtools\u001b[0m\n",
            "\u001b[34mDownloading pathtools-0.1.2.tar.gz (11 kB)\u001b[0m\n",
            "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
            "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 2)) (62.3.2)\u001b[0m\n",
            "\u001b[34mCollecting docker-pycreds>=0.4.0\u001b[0m\n",
            "\u001b[34mDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\u001b[0m\n",
            "\u001b[34mCollecting GitPython!=3.1.29,>=1.0.0\u001b[0m\n",
            "\u001b[34mDownloading GitPython-3.1.31-py3-none-any.whl (184 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.3/184.3 kB 32.6 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 4)) (2022.5.18.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 4)) (2.0.4)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 4)) (3.3)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->-r requirements.txt (line 4)) (1.26.9)\u001b[0m\n",
            "\u001b[34mCollecting filelock\u001b[0m\n",
            "\u001b[34mDownloading filelock-3.12.1-py3-none-any.whl (10 kB)\u001b[0m\n",
            "\u001b[34mCollecting regex!=2019.12.17\u001b[0m\n",
            "\u001b[34mDownloading regex-2023.6.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 772.3/772.3 kB 64.9 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\u001b[0m\n",
            "\u001b[34mDownloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 93.4 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting safetensors>=0.3.1\u001b[0m\n",
            "\u001b[34mDownloading safetensors-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 79.4 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.8.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 6)) (2.2.0)\u001b[0m\n",
            "\u001b[34mCollecting ansi2html\u001b[0m\n",
            "\u001b[34mDownloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\u001b[0m\n",
            "\u001b[34mCollecting arrow\u001b[0m\n",
            "\u001b[34mDownloading arrow-1.2.3-py3-none-any.whl (66 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.4/66.4 kB 17.6 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting flask\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.3.2-py3-none-any.whl (96 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.9/96.9 kB 19.5 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting flask_restful\u001b[0m\n",
            "\u001b[34mDownloading Flask_RESTful-0.3.10-py2.py3-none-any.whl (26 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 7)) (1.16.0)\u001b[0m\n",
            "\u001b[34mCollecting termcolor\u001b[0m\n",
            "\u001b[34mDownloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from nvgpu->-r requirements.txt (line 7)) (0.8.9)\u001b[0m\n",
            "\u001b[34mCollecting pynvml\u001b[0m\n",
            "\u001b[34mDownloading pynvml-11.5.0-py3-none-any.whl (53 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 11.7 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: docutils<0.17,>=0.10 in /opt/conda/lib/python3.8/site-packages (from awscli->-r requirements.txt (line 8)) (0.16)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: rsa<4.8,>=3.1.2 in /opt/conda/lib/python3.8/site-packages (from awscli->-r requirements.txt (line 8)) (4.7.2)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from awscli->-r requirements.txt (line 8)) (0.6.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: colorama<0.4.5,>=0.2.5 in /opt/conda/lib/python3.8/site-packages (from awscli->-r requirements.txt (line 8)) (0.4.4)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: botocore==1.27.1 in /opt/conda/lib/python3.8/site-packages (from awscli->-r requirements.txt (line 8)) (1.27.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from botocore==1.27.1->awscli->-r requirements.txt (line 8)) (1.0.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore==1.27.1->awscli->-r requirements.txt (line 8)) (2.8.2)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 9)) (0.2.9)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 9)) (0.2.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 9)) (0.1.5)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 9)) (1.0.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: importlib-metadata<2.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 9)) (1.7.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: attrs==20.3.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 9)) (20.3.0)\u001b[0m\n",
            "\u001b[34mCollecting gitdb<5,>=4.0.1\u001b[0m\n",
            "\u001b[34mDownloading gitdb-4.0.10-py3-none-any.whl (62 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 17.1 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<2.0,>=1.4.0->sagemaker->-r requirements.txt (line 9)) (3.8.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets->-r requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from rsa<4.8,>=3.1.2->awscli->-r requirements.txt (line 8)) (0.4.8)\u001b[0m\n",
            "\u001b[34mCollecting urllib3<1.27,>=1.21.1\u001b[0m\n",
            "\u001b[34mDownloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.1/143.1 kB 30.8 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting yarl<2.0,>=1.0\u001b[0m\n",
            "\u001b[34mDownloading yarl-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 266.9/266.9 kB 38.3 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting multidict<7.0,>=4.5\u001b[0m\n",
            "\u001b[34mDownloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 22.0 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting aiosignal>=1.1.2\u001b[0m\n",
            "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
            "\u001b[34mCollecting frozenlist>=1.1.1\u001b[0m\n",
            "\u001b[34mDownloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 35.5 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
            "\u001b[34mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
            "\u001b[34mCollecting blinker>=1.6.2\u001b[0m\n",
            "\u001b[34mDownloading blinker-1.6.2-py3-none-any.whl (13 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 7)) (3.1.2)\u001b[0m\n",
            "\u001b[34mCollecting Werkzeug>=2.3.3\u001b[0m\n",
            "\u001b[34mDownloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.5/242.5 kB 41.7 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mCollecting itsdangerous>=2.1.2\u001b[0m\n",
            "\u001b[34mDownloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\u001b[0m\n",
            "\u001b[34mCollecting flask\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.3.1-py3-none-any.whl (96 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.0/97.0 kB 22.7 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.3.0-py3-none-any.whl (96 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.0/97.0 kB 20.0 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.2.5-py3-none-any.whl (101 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.8/101.8 kB 25.8 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.2.4-py3-none-any.whl (101 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.7/101.7 kB 26.4 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.2.3-py3-none-any.whl (101 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.8/101.8 kB 22.8 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.2.2-py3-none-any.whl (101 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.5/101.5 kB 26.7 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.2.1-py3-none-any.whl (101 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.5/101.5 kB 26.0 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.2.0-py3-none-any.whl (101 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.1/101.1 kB 26.0 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.1.3-py3-none-any.whl (95 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.6/95.6 kB 22.1 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: Werkzeug>=2.0 in /opt/conda/lib/python3.8/site-packages (from flask->nvgpu->-r requirements.txt (line 7)) (2.1.2)\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.1.2-py3-none-any.whl (95 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.2/95.2 kB 19.1 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.1.1-py3-none-any.whl (95 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.2/95.2 kB 25.2 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mDownloading Flask-2.1.0-py3-none-any.whl (95 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.2/95.2 kB 20.9 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pytz in /opt/conda/lib/python3.8/site-packages (from flask_restful->nvgpu->-r requirements.txt (line 7)) (2021.3)\u001b[0m\n",
            "\u001b[34mCollecting aniso8601>=0.82\u001b[0m\n",
            "\u001b[34mDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\u001b[0m\n",
            "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 14.3 MB/s eta 0:00:00\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: ppft>=1.7.6.5 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker->-r requirements.txt (line 9)) (1.7.6.5)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pox>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker->-r requirements.txt (line 9)) (0.3.1)\u001b[0m\n",
            "\u001b[34mCollecting smmap<6,>=3.0.1\u001b[0m\n",
            "\u001b[34mDownloading smmap-5.0.0-py3-none-any.whl (24 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from Jinja2>=3.1.2->flask->nvgpu->-r requirements.txt (line 7)) (2.1.1)\u001b[0m\n",
            "\u001b[34mBuilding wheels for collected packages: nvgpu, pathtools\u001b[0m\n",
            "\u001b[34mBuilding wheel for nvgpu (setup.py): started\u001b[0m\n",
            "\u001b[34mBuilding wheel for nvgpu (setup.py): finished with status 'done'\u001b[0m\n",
            "\u001b[34mCreated wheel for nvgpu: filename=nvgpu-0.10.0-py3-none-any.whl size=9543 sha256=b94ea4785fb102ea401b8578c3248e00a2b707d0bce921fbe4459b407d286c65\u001b[0m\n",
            "\u001b[34mStored in directory: /root/.cache/pip/wheels/b2/af/59/68aadfe227fc8fd079544b719d3aaaf4067d68990bbc2c79e5\u001b[0m\n",
            "\u001b[34mBuilding wheel for pathtools (setup.py): started\u001b[0m\n",
            "\u001b[34mBuilding wheel for pathtools (setup.py): finished with status 'done'\u001b[0m\n",
            "\u001b[34mCreated wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=72609232f646d9d1e68a7f99f508e9c4b2c7ebc6cfd6027cc00cd6edcfb0f596\u001b[0m\n",
            "\u001b[34mStored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\u001b[0m\n",
            "\u001b[34mSuccessfully built nvgpu pathtools\u001b[0m\n",
            "\u001b[34mInstalling collected packages: tokenizers, safetensors, pathtools, appdirs, aniso8601, xxhash, urllib3, termcolor, smmap, setproctitle, regex, pynvml, multidict, itsdangerous, frozenlist, filelock, docker-pycreds, async-timeout, ansi2html, yarl, xgboost, sentry-sdk, gitdb, flask, arrow, aiosignal, responses, huggingface-hub, GitPython, flask_restful, aiohttp, wandb, transformers, nvgpu, datasets\u001b[0m\n",
            "\u001b[34mAttempting uninstall: urllib3\u001b[0m\n",
            "\u001b[34mFound existing installation: urllib3 1.26.9\u001b[0m\n",
            "\u001b[34mUninstalling urllib3-1.26.9:\u001b[0m\n",
            "\u001b[34mSuccessfully uninstalled urllib3-1.26.9\u001b[0m\n",
            "\n",
            "2023-06-10 15:02:06 Uploading - Uploading generated training model\n",
            "2023-06-10 15:02:06 Completed - Training job completed\n",
            "\u001b[34mSuccessfully installed GitPython-3.1.31 aiohttp-3.8.4 aiosignal-1.3.1 aniso8601-9.0.1 ansi2html-1.8.0 appdirs-1.4.4 arrow-1.2.3 async-timeout-4.0.2 datasets-2.12.0 docker-pycreds-0.4.0 filelock-3.12.1 flask-2.1.0 flask_restful-0.3.10 frozenlist-1.3.3 gitdb-4.0.10 huggingface-hub-0.15.1 itsdangerous-2.1.2 multidict-6.0.4 nvgpu-0.10.0 pathtools-0.1.2 pynvml-11.5.0 regex-2023.6.3 responses-0.18.0 safetensors-0.3.1 sentry-sdk-1.25.1 setproctitle-1.3.2 smmap-5.0.0 termcolor-2.3.0 tokenizers-0.13.3 transformers-4.30.1 urllib3-1.26.16 wandb-0.15.4 xgboost-1.7.5 xxhash-3.2.0 yarl-1.9.2\u001b[0m\n",
            "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:56,128 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:56,129 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:56,132 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:56,143 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:56,154 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:56,163 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
            "\u001b[34mTraining Env:\u001b[0m\n",
            "\u001b[34m{\n",
            "    \"additional_framework_parameters\": {},\n",
            "    \"channel_input_dirs\": {\n",
            "        \"testing\": \"/opt/ml/input/data/testing\",\n",
            "        \"training\": \"/opt/ml/input/data/training\"\n",
            "    },\n",
            "    \"current_host\": \"algo-1\",\n",
            "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
            "    \"hosts\": [\n",
            "        \"algo-1\"\n",
            "    ],\n",
            "    \"hyperparameters\": {\n",
            "        \"epochs\": 2,\n",
            "        \"num_labels\": 2\n",
            "    },\n",
            "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
            "    \"input_data_config\": {\n",
            "        \"testing\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        },\n",
            "        \"training\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        }\n",
            "    },\n",
            "    \"input_dir\": \"/opt/ml/input\",\n",
            "    \"is_master\": true,\n",
            "    \"job_name\": \"pytorch-training-2023-06-10-14-58-43-916\",\n",
            "    \"log_level\": 20,\n",
            "    \"master_hostname\": \"algo-1\",\n",
            "    \"model_dir\": \"/opt/ml/model\",\n",
            "    \"module_dir\": \"s3://sagemaker-us-east-1-060110317448/pytorch-training-2023-06-10-14-58-43-916/source/sourcedir.tar.gz\",\n",
            "    \"module_name\": \"train_deploy\",\n",
            "    \"network_interface_name\": \"eth0\",\n",
            "    \"num_cpus\": 4,\n",
            "    \"num_gpus\": 0,\n",
            "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
            "    \"output_dir\": \"/opt/ml/output\",\n",
            "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
            "    \"resource_config\": {\n",
            "        \"current_host\": \"algo-1\",\n",
            "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
            "        \"current_group_name\": \"homogeneousCluster\",\n",
            "        \"hosts\": [\n",
            "            \"algo-1\"\n",
            "        ],\n",
            "        \"instance_groups\": [\n",
            "            {\n",
            "                \"instance_group_name\": \"homogeneousCluster\",\n",
            "                \"instance_type\": \"ml.m5.xlarge\",\n",
            "                \"hosts\": [\n",
            "                    \"algo-1\"\n",
            "                ]\n",
            "            }\n",
            "        ],\n",
            "        \"network_interface_name\": \"eth0\"\n",
            "    },\n",
            "    \"user_entry_point\": \"train_deploy.py\"\u001b[0m\n",
            "\u001b[34m}\u001b[0m\n",
            "\u001b[34mEnvironment variables:\u001b[0m\n",
            "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
            "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
            "\u001b[34mSM_HPS={\"epochs\":2,\"num_labels\":2}\u001b[0m\n",
            "\u001b[34mSM_USER_ENTRY_POINT=train_deploy.py\u001b[0m\n",
            "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
            "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
            "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
            "\u001b[34mSM_CHANNELS=[\"testing\",\"training\"]\u001b[0m\n",
            "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
            "\u001b[34mSM_MODULE_NAME=train_deploy\u001b[0m\n",
            "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
            "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
            "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
            "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
            "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
            "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
            "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
            "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-060110317448/pytorch-training-2023-06-10-14-58-43-916/source/sourcedir.tar.gz\u001b[0m\n",
            "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":2,\"num_labels\":2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2023-06-10-14-58-43-916\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-060110317448/pytorch-training-2023-06-10-14-58-43-916/source/sourcedir.tar.gz\",\"module_name\":\"train_deploy\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_deploy.py\"}\u001b[0m\n",
            "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"2\",\"--num_labels\",\"2\"]\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
            "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
            "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
            "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
            "\u001b[34mSM_HP_NUM_LABELS=2\u001b[0m\n",
            "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
            "\u001b[34mInvoking script with the following command:\u001b[0m\n",
            "\u001b[34m/opt/conda/bin/python3.8 train_deploy.py --epochs 2 --num_labels 2\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:56,187 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:56,187 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
            "\u001b[34m2023-06-10 15:01:56,188 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
            "Training seconds: 102\n",
            "Billable seconds: 57\n",
            "Managed Spot Training savings: 44.1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Host the model on an Amazon SageMaker Endpoint"
      ],
      "metadata": {
        "id": "9__tTOWi5bVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(estimator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_Ju5zwq8zcq",
        "outputId": "d4f4e21a-7eff-4cbd-a2d6-c09410503b0b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sagemaker.pytorch.estimator.PyTorch object at 0x7f0978548400>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
      ],
      "metadata": {
        "id": "9A_Fn3LL1xQ6"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jIADiMGB1xNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-O6jNgFToOm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m5mlE_tmoOkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "445dRTPtoOh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.delete_endpoint()"
      ],
      "metadata": {
        "id": "QMkU67HpoOf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "* - https://www.kaggle.com/code/jdparsons/tweet-cleaner\n",
        "* - https://www.kaggle.com/code/vinayakshanawad/aws-sagemaker-train-deploy-update-a-bert-model\n",
        "* - https://github.com/vinayak-shanawad/AWS-SageMaker-Examples/tree/main/05_SageMakerExperimentsWithWandB"
      ],
      "metadata": {
        "id": "C6zNytDTj7Kj"
      }
    }
  ]
}